{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0964a20-04d8-49c6-9b9b-7f9a7dd6b340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze â†’ Silver (Delta Live Tables Pipeline)\n",
    "\n",
    "This notebook defines **managed streaming tables** using Delta Live Tables.\n",
    "It must be attached to a **DLT pipeline** and will not run as a standard Spark job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89df9373-c383-4576-9794-ef4f87cde27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### `Lakeflow Declarative Pipelines` / `Delta Live Tables`\n",
    "A managed system in Databricks where you define what tables you want, and it automatically builds, updates, and monitors the data pipeline for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bb8df14-2742-4469-a7aa-579131f184b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "> **Note:**  \n",
    "> The below code will not run directly on the cluster.  \n",
    "> It must be executed through a **Delta Live Tables pipeline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f08895e5-4c0f-49f6-be87-eb3f48375a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "995a91cd-a307-4bb2-812e-426b1c9d47ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reads streaming data from the Bronze Delta table\n",
    "# and creates a Silver table managed by Delta Live Tables.\n",
    "@dlt.table(\n",
    "    name=\"staging_bookings\"\n",
    ")\n",
    "def staging_bookings():\n",
    "    df = spark.readStream.format(\"delta\") \\\n",
    "        .load(\"/Volumes/flightsproj/bronze/bronzevolume/bookings/data\")\n",
    "    return df\n",
    "\n",
    "# This will laod the table incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf6337c4-a84d-4ed4-9a06-0b73e1b80345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.View(name=\"transform_bookings\")\n",
    "\n",
    "def transform_bookings():\n",
    "    # Spark allow to read streaming data from the Bronze Delta table wihtout even running it at time of devlopment\n",
    "    df = spark.readStream.table(staging_bookings)\n",
    "\n",
    "    # Transform code\n",
    "    df = df.withColumn('amount', col('amount').cast(DoubleType()))\\\n",
    "           .withColumn('booking_date', to_date(col('booking_date')))\\\n",
    "           .drop(\"_rescued_data\")\\\n",
    "           .withColumn('modified_date', current_timestamp())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a872abc-f3fc-4aee-845b-f30eb1334a2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Decorator                 | Behavior                     |\n",
    "| ------------------------- | ---------------------------- |\n",
    "| `@dlt.expect_all`         | Log violations only          |\n",
    "| `@dlt.expect_all_or_drop` | Drop bad rows                |\n",
    "| `@dlt.expect_all_or_fail` | Stop pipeline if any bad row |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2d1e0ff-e52b-4d29-9021-a14ff627d61e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lets use @dlt.expect_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a751244-95f9-4c28-bb67-55d323b794fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rules = {\n",
    "    'rule1' : 'BOOKING_ID IS NOT NULL',\n",
    "    'rule2' : 'AIRPORT_ID IS NOT NULL',\n",
    "    'rule3' : 'FLIGHT_ID IS NOT NULL',\n",
    "    'rule4' : 'PASSENGER_ID IS NOT NULL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5848bea-31b6-48c3-891c-b7f5b22075f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the above data to streaming table\n",
    "\n",
    "@dlt.table(name=\"silver_bookings\")\n",
    "\n",
    "@dlt.expect_all_or_drop(rules) # Adding expectations all rules should be satisfied or dropped\n",
    "def silver_bookings():\n",
    "    df = dlt.read(transform_bookings)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_to_silver_dlt_pipeline_sample",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
